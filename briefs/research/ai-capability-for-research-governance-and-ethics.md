# AI Capability for Research Governance & Ethics

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for research governance and ethics roles responsible for safeguarding integrity, accountability, and public trust in research contexts where artificial intelligence increasingly shapes research design, analysis, interpretation, and dissemination.

It is intended for:

- research ethics committees and chairs  
- research governance and compliance teams  
- research integrity and assurance leads  
- data governance and information security roles  
- funder-facing and regulatory liaison staff  

This is not a technical guide or a policy template.  
It is a capability briefing to support informed judgement, proportionate oversight, and defensible ethical decision-making when AI becomes part of research practice.

---

## 2. Why AI capability matters in research governance and ethics

AI is now embedded — often implicitly — across the research lifecycle:

- shaping literature review and synthesis  
- supporting data exploration and analysis  
- influencing interpretation and framing  
- accelerating reporting and dissemination  

These uses can bring efficiency and insight, but they also introduce novel ethical and governance challenges that traditional review processes were not designed to address.

For research governance and ethics roles, the key challenge is not to regulate AI tools, but to ensure that research practices involving AI remain transparent, accountable, equitable, and aligned with disciplinary and societal expectations.

AI capability enables oversight that is credible, proportionate, and trusted — without stifling legitimate research innovation.

---

## 3. Common risks and blind spots in research governance

Across institutions, recurring risks appear when AI capability is underdeveloped at governance level:

- **Invisible AI use:** AI shaping research processes without disclosure or discussion.  
- **Ethics lag:** review processes not keeping pace with evolving research practice.  
- **Ambiguous responsibility:** unclear accountability for AI-influenced decisions.  
- **Data exposure risks:** inappropriate use of sensitive, proprietary, or unpublished data.  
- **Inconsistent standards:** uneven expectations across disciplines or projects.  
- **Over-proceduralisation:** adding layers of approval without improving ethical judgement.  

These risks reflect capability gaps, not intentional misuse.

---

## 4. Applying the six domains of AI capability in research governance and ethics

The AI Capability Framework provides a shared lens for evolving research oversight responsibly.

### 4.1 AI Awareness & Orientation

Governance and ethics roles need a grounded understanding of how AI systems operate and fail.

This includes:

- recognising probabilistic outputs and uncertainty  
- understanding common risks such as bias and hallucination  
- avoiding assumptions that AI outputs are neutral or authoritative  

This domain supports informed ethical scrutiny, not technical assessment.

---

### 4.2 Human–AI Co-Agency

Research accountability must remain human-owned.

AI capability in this domain involves:

- clarifying where researchers retain responsibility for judgement and interpretation  
- ensuring AI does not obscure authorship or intellectual contribution  
- reinforcing that ethical accountability cannot be delegated to systems  

Clear co-agency underpins research integrity.

---

### 4.3 Applied Practice & Innovation

Ethics and governance must accommodate legitimate innovation.

This domain supports:

- proportionate oversight based on research context and risk  
- enabling responsible experimentation within clear ethical boundaries  
- learning from emerging practices rather than reacting after incidents  

Capability here allows governance to guide innovation, not block it.

---

### 4.4 Ethics, Equity & Impact

AI can amplify structural inequalities and ethical blind spots.

Governance capability includes:

- scrutinising differential impacts on participants and communities  
- considering downstream societal implications of AI-supported research  
- ensuring inclusion and justice are embedded in review processes  

Ethics here is an ongoing evaluative practice, not a one-time check.

---

### 4.5 Decision-Making & Governance

This domain is central to research oversight.

AI capability involves:

- requiring transparency about AI use in research proposals and methods  
- documenting ethical rationale and conditions of approval  
- aligning local decisions with funder, publisher, and regulatory expectations  

Effective governance focuses on traceable, defensible judgement.

---

### 4.6 Reflection, Learning & Renewal

Research ethics must evolve with practice.

This includes: 

- reviewing how AI is changing research norms  
- updating guidance and review criteria iteratively  
- supporting learning across ethics committees and governance teams  

This domain ensures oversight remains credible and adaptive.

---

## 5. Practical actions for research governance and ethics roles

The following actions strengthen AI capability in research oversight:

- **Make AI use discussable in review processes**  
  Encourage explicit reflection rather than hidden practice.

- **Focus on responsibility, not tools**  
  Ask who is accountable for AI-supported decisions.

- **Adopt a risk-based approach**  
  Tailor scrutiny to context, data sensitivity, and potential impact.

- **Embed equity considerations**  
  Surface differential effects on participants and communities.

- **Document ethical reasoning**  
  Record how AI considerations shaped approval decisions.

- **Review and update guidance regularly**  
  Treat AI ethics as a living governance concern.

---

## 6. Signals of mature AI capability in research governance

Institutions with strong AI capability in research governance typically show:

- transparent disclosure of AI use in research  
- consistent ethical standards across disciplines  
- confidence in responding to funders and regulators  
- proportionate, context-sensitive oversight  
- clear accountability for research decisions  
- a culture of ethical learning rather than defensive compliance  

These signals indicate ethical maturity, not rigidity.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to research governance and ethics.

To deepen this work, governance and ethics roles may explore:

- the full AI Capability Framework (PDF)  
- the Application Handbook for implementation pathways  
- Practice Guides focused on governance and decision-making  
- facilitated ethics and governance capability workshops  

The Framework provides structure.  
Research governance provides ethical judgement and public accountability.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
