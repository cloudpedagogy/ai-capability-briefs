# AI Capability for Programme Directors

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for Programme Directors responsible for academic quality, curriculum coherence, assessment integrity, student experience, and regulatory alignment in an environment where artificial intelligence is now part of everyday academic practice.

This is not a guide to AI tools.  
It is a capability briefing to support the judgement, oversight, and decision-making required to lead programmes responsibly, confidently, and strategically in the presence of AI.

---

## 2. Why AI capability matters at programme level

AI is already shaping how students write, research, analyse, plan, and study. It is also influencing how staff design assessments, provide feedback, analyse performance, and manage workloads.

For Programme Directors, this creates a shift in responsibility:

- decisions about AI are no longer isolated to individual modules  
- inconsistencies across a programme create confusion, risk, and inequity  
- assessment integrity, learning outcomes, and graduate attributes must be considered in relation to AI use, not separately from it  

AI capability at programme level is therefore about:

- coherence, not enforcement  
- judgement, not policing  
- intentional design, not reactive fixes  

Programme Directors are uniquely positioned to provide this coherence.

---

## 3. Common risks and blind spots for Programme Directors

Across institutions, several recurring risks appear at programme level:

- **Fragmentation:** different modules adopting conflicting assumptions about AI use  
- **Assessment drift:** assessments no longer reliably measuring intended learning outcomes  
- **Unclear expectations:** students receiving mixed or implicit messages about acceptable AI use  
- **Over-reliance on detection:** treating AI as a compliance problem rather than a design challenge  
- **Equity gaps:** uneven student access to guidance, support, and digital confidence  
- **Policy–practice mismatch:** institutional guidance not translating into programme-level decisions  

These risks are rarely solved by banning tools or issuing blanket rules.  
They require capability-led leadership.

---

## 4. Applying the six domains of AI capability at programme level

The CloudPedagogy AI Capability Framework offers Programme Directors a structured way to lead AI-aware curriculum and assessment design.

### 4.1 AI Awareness & Orientation

Programme Directors need a shared baseline understanding of how AI systems generate outputs, their limitations, and where they introduce risk.

At programme level, this means:

- understanding where AI use meaningfully affects learning outcomes  
- recognising differences between acceptable support and inappropriate substitution  
- avoiding over-simplified narratives (for example, “AI equals cheating”)  

Capability here supports informed oversight, not technical mastery.

---

### 4.2 Human–AI Co-Agency

AI capability is not about replacing academic judgement. It is about clarifying roles.

For Programme Directors, this involves:

- defining where human judgement remains essential (for example, evaluation, synthesis, professional reasoning)  
- ensuring assessments require meaningful human contribution  
- supporting staff to design tasks where AI use is transparent and intentional  

Clear co-agency reduces ambiguity for both staff and students.

---

### 4.3 Applied Practice & Innovation

Programme Directors play a critical role in enabling safe, aligned experimentation.

This includes:

- encouraging module teams to test AI-aware assessment designs  
- sharing effective practices across the programme  
- supporting innovation that strengthens learning rather than undermining it  

Innovation is most effective when it is coordinated at programme level, not left to individual trial and error.

---

### 4.4 Ethics, Equity & Impact

Programme-level decisions shape student experience and fairness.

Key considerations include:

- whether expectations around AI use are clear and equitable across modules  
- whether assessments disadvantage students with lower digital confidence  
- whether accessibility and inclusion are actively considered in AI-related decisions  

Programme Directors ensure that ethical and equity considerations are embedded, not retrofitted.

---

### 4.5 Decision-Making & Governance

Programme Directors sit at a crucial governance junction.

AI capability here involves:

- translating institutional policy into programme-level guidance  
- documenting assessment decisions that involve AI considerations  
- ensuring consistency with accreditation, quality assurance, and external expectations  

Good governance is about traceable, defensible judgement, not rigid control.

---

### 4.6 Reflection, Learning & Renewal

AI-related practice will continue to evolve.

Programme Directors support sustainable capability by:

- reviewing the programme-level impact of AI-related changes  
- creating space for staff reflection and shared learning  
- treating AI capability as an ongoing developmental process  

This domain ensures the programme remains adaptive rather than reactive.

---

## 5. Practical actions for Programme Directors

The following actions strengthen AI capability without adding unnecessary burden:

- **Create programme-level clarity**  
  Agree shared principles for AI use across modules, aligned to learning outcomes.

- **Review assessment coherence**  
  Check whether assessments still measure what the programme intends students to learn.

- **Support staff confidence**  
  Facilitate structured conversations rather than issuing rules.

- **Align with institutional guidance**  
  Ensure programme decisions reflect policy while remaining context-sensitive.

- **Document decisions**  
  Maintain a clear record of how AI considerations informed programme design.

- **Communicate transparently with students**  
  Make expectations explicit and consistent across the programme.

---

## 6. Signals of mature AI capability at programme level

A programme with strong AI capability typically shows the following signs:

- students receive consistent guidance across modules  
- assessments emphasise judgement, reasoning, and synthesis  
- staff feel supported rather than monitored  
- AI use is discussed openly and constructively  
- decisions are explainable to quality assurance processes, external examiners, and accrediting bodies  
- the programme adapts without frequent crisis responses  

These signals indicate capability maturity rather than compliance.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) at programme leadership level.

To deepen this work, Programme Directors may wish to explore:

- the full AI Capability Framework (PDF)  
- the Application Handbook for structured implementation  
- Practice Guides related to teaching, assessment, and governance  
- AI capability workshops or facilitated programme reviews  

The Framework provides the shared language.  
Programme leadership provides the judgement.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
