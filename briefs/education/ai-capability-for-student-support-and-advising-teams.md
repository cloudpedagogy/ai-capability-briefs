# AI Capability for Student Support & Advising Teams

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for Student Support, Academic Advising, Pastoral Care, Wellbeing, Careers, and related professional services teams who support students’ academic progress, decision-making, and wellbeing in contexts where artificial intelligence increasingly shapes how students study, plan, and seek guidance.

It is intended for teams involved in:

- academic advising and progression support  
- pastoral care and wellbeing services  
- careers guidance and employability support  
- accessibility, disability, and inclusion services  
- frontline student-facing support roles  

This is not a technical guide to AI tools or chatbots.  
It is a capability briefing to support ethical judgement, consistency, and defensible support practice when AI becomes part of students’ everyday learning and decision-making.

---

## 2. Why AI capability matters for student support and advising

Students are increasingly using AI to:

- plan study strategies and workloads  
- interpret assessment feedback and grades  
- draft emails, appeals, or personal statements  
- explore career options and pathways  
- seek emotional or motivational support  

Student support teams are therefore asked to:

- respond to AI-shaped questions and expectations  
- advise students without full visibility of AI use  
- balance support with academic integrity considerations  
- operate within safeguarding, wellbeing, and duty-of-care frameworks  

Without explicit AI capability, support teams risk:

- inconsistent advice across services  
- blurred boundaries of responsibility  
- unintended inequities in support  
- exposure to ethical or safeguarding concerns  

AI capability enables student-facing teams to support learners confidently, fairly, and responsibly.

---

## 3. Common risks and blind spots in AI-influenced student support

Across institutions, recurring challenges appear:

- **Over-trust in AI advice:** students deferring to AI-generated guidance over professional support  
- **Boundary confusion:** uncertainty about appropriate AI use in pastoral or wellbeing contexts  
- **Inconsistent messaging:** different teams giving conflicting advice about AI  
- **Equity gaps:** uneven access to AI literacy and guidance  
- **Emotional displacement:** students seeking support from AI rather than people  
- **Safeguarding risk:** AI use intersecting with vulnerability without oversight  

These risks arise when AI enters student life faster than support capability adapts.

---

## 4. Applying the six domains of AI capability in student support roles

The AI Capability Framework provides a structured way to navigate AI-related student support responsibly.

### 4.1 AI Awareness & Orientation

Support staff need a realistic understanding of how students use AI.

This includes:

- recognising common student-facing AI applications  
- understanding limitations and risks of AI-generated advice  
- avoiding assumptions about student competence or intent  

This domain supports informed guidance, not technical instruction.

---

### 4.2 Human–AI Co-Agency

Student support must remain human-centred.

AI capability here involves:

- reinforcing that professional judgement and care remain human-led  
- clarifying that AI tools do not replace institutional support  
- helping students understand appropriate reliance on AI  

Clear co-agency protects student wellbeing and trust.

---

### 4.3 Applied Practice & Innovation

AI can support student services when used deliberately.

This domain supports:

- using AI to streamline administrative preparation  
- supporting reflective conversations about AI use  
- exploring responsible digital literacy initiatives  

Innovation is beneficial when it enhances support capacity without reducing care quality.

---

### 4.4 Ethics, Equity & Impact

Student support roles carry heightened ethical responsibility.

AI capability in this domain includes:

- recognising differential impacts on vulnerable or marginalised students  
- ensuring AI-related advice does not disadvantage particular groups  
- maintaining confidentiality, consent, and safeguarding standards  

Ethical support requires vigilance about unintended harm.

---

### 4.5 Decision-Making & Governance

Student services operate within regulatory and institutional frameworks.

AI capability here involves:

- knowing when AI-related issues require escalation  
- documenting advice and decisions clearly  
- aligning practice with institutional policy and duty-of-care obligations  

Good governance protects students and staff alike.

---

### 4.6 Reflection, Learning & Renewal

Student needs and technologies evolve rapidly.

Capability is strengthened when teams:

- reflect on emerging patterns in AI-related student queries  
- share learning across services  
- update guidance as tools and behaviours change  

This domain supports resilient, adaptive student support systems.

---

## 5. Practical actions for student support and advising teams

The following actions strengthen AI capability in student-facing roles:

- **Acknowledge AI openly**  
  Create space for honest discussion about student AI use.

- **Reinforce human support**  
  Emphasise the value of professional advice and care.

- **Clarify boundaries**  
  Be explicit about what support services can and cannot advise on.

- **Watch for vulnerability signals**  
  Recognise when AI reliance may mask deeper issues.

- **Align messaging across services**  
  Reduce confusion through shared guidance and language.

- **Document and escalate appropriately**  
  Protect students and staff through clear records and processes.

---

## 6. Signals of mature AI capability in student support

Student support systems with strong AI capability typically demonstrate:

- consistent, compassionate advice across services  
- clarity about AI’s role in student decision-making  
- equitable access to guidance and support  
- confidence in handling complex or sensitive cases  
- strong safeguarding and governance alignment  
- learning-oriented service improvement  

These signals reflect care maturity, not technological sophistication.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to student support and advising contexts.

To deepen this work, teams may explore:

- the full AI Capability Framework (PDF)  
- Practice Guides focused on equity and high-impact contexts  
- the Application Handbook for institutional implementation  
- facilitated cross-service capability workshops  

The Framework provides structure.  
Student support teams provide care, judgement, and trust.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
